<?xml version="1.0" encoding="ISO-8859-1"?>
<pipeline>
<vertex>
<![CDATA[#version 410 

in vec3 vertex_worldSpace;
in vec3 normal_worldSpace;
in vec2 textureCoordinate_input;

uniform mat4 mvMatrix;
uniform mat4 pMatrix;
uniform mat3 normalMatrix; //mv matrix without translation

uniform vec4 lightPosition_camSpace; //light Position in camera space

uniform vec4 ambient;
uniform vec4 diffuse;
uniform vec4 specular;
uniform float shininess;
uniform float ambientCoefficent;
uniform float diffuseCoefficent;
uniform float specularCoefficent;

out data
{
  vec4 position_camSpace;
  vec3 normal_camSpace;
  vec2 textureCoordinate;
  vec4 color;
}vertexInOut;

//Vertex shader compute the vectors per vertex
void main(void)
{
  //Put the vertex in the correct coordinate system by applying the model view matrix
  vec4 vertex_camSpace = mvMatrix*vec4(vertex_worldSpace,1.0f); 
  vertexInOut.position_camSpace = vertex_camSpace;
  
  //Apply the model-view transformation to the normal (only rotation, no translation)
  //Normals put in the camera space
  vertexInOut.normal_camSpace = normalize(normalMatrix*normal_worldSpace);
  
  //we need to make sure that the normals and texture coordinates
  //aren't optimised away, 
  //so we have to use them somehow.
  //Uniforms and array objects that are nor used for 
  //the final output(!) are  removed during 
  //glsl compilation regardless if you assign them. 
  vec4 workaround = 
		vec4((vertexInOut.normal_camSpace.x + textureCoordinate_input.x)*0.0001, 0, 0, 1);       

  // Normal to vertex.
  vec3 n = vertexInOut.normal_camSpace;
  // Distance of light to vertex.
  vec3 lightToTeapot = lightPosition_camSpace.xyz-vertexInOut.position_camSpace.xyz;
  // Normalized direction.
  vec3 l = normalize(lightToTeapot);

  // Normalized direction from camera to teapot.
  vec3 v = normalize(vec3(0,0,0) - vertexInOut.position_camSpace.xyz);
  // Reflection of l in the normal.
  vec3 r = reflect(-l, n);

  float attenuation = 5000 / (4 * 3.14 * pow(length(lightToTeapot), 2));
  float normalizationFactor = (shininess + 2) / (2 * 3.14);
 
  vec4 ambi = ambient * ambientCoefficent; 
  vec4 diff = diffuse * diffuseCoefficent * max(dot(n,l), 0);
  vec4 spec = specular * specularCoefficent * pow(max(dot(r, v), 0), shininess) * normalizationFactor;
  
  vec4 total = ambi + (spec + diff) * attenuation;

  //forwarding pure red as RGBA color
  //Try to use the normals as RGB color or the texture coordiantes!
  //vertexInOut.color = vec4(1.0, 0.0, 0.0, 1.0);
  vertexInOut.color = total;

  //a negligible contribution from normals and texcoords is added 
  //to ensure these array objects are not optimsed away 
  vertexInOut.color += workaround;
  
  //Texture coordinate
  vertexInOut.textureCoordinate = textureCoordinate_input;
  
  gl_Position = pMatrix * vertex_camSpace;
}





]]></vertex>
<geom>
<![CDATA[#version 410 

layout(triangles) in;
layout(triangle_strip, max_vertices = 3) out;

uniform mat4 mvMatrix;
uniform mat4 pMatrix;
uniform mat3 normalMatrix; //mv matrix without translation

uniform vec4 lightPosition_camSpace; //light Position in camera space

uniform int time;

in data
{
  vec4 position_camSpace;
  vec3 normal_camSpace;
  vec2 textureCoordinate;
  vec4 color;
}vertexIn[3];

out fragmentData
{
  vec4 position_camSpace;
  vec3 normal_camSpace;
  vec2 textureCoordinate;
  vec4 color;
} frag;

void main() {
  for (int i = 0; i < 3; i++) { // You used triangles, so it's always 3
    gl_Position = gl_in[i].gl_Position;
    frag.position_camSpace = vertexIn[i].position_camSpace;
    frag.normal_camSpace = vertexIn[i].normal_camSpace;
    frag.textureCoordinate = vertexIn[i].textureCoordinate;
    frag.color = vertexIn[i].color;
	EmitVertex();
  }
  EndPrimitive();
 }





]]></geom>
<frag>
<![CDATA[#version 410

uniform vec4 ambient;
uniform vec4 diffuse;
uniform vec4 specular;
uniform float shininess;
uniform float ambientCoefficent;
uniform float diffuseCoefficent;
uniform float specularCoefficent;

uniform vec4 lightPosition_camSpace; //light Position in camera space

in fragmentData
{
  vec4 position_camSpace;
  vec3 normal_camSpace;
  vec2 textureCoordinate;
  vec4 color;
} frag;

out vec4 fragColor; 

//Fragment shader computes the final color
void main(void)
{
  fragColor =  frag.color;
}





]]></frag>
<R2TVert>
<![CDATA[#version 410

layout(location = 0) in vec4 vertex_worldSpace;
uniform mat4 mvMatrix;
uniform mat4 pMatrix;

//in vec4 vertex_worldSpace;
in vec2 textureCoordinate_input;

out vec2 varyingTextureCoordinate;

//Vertex shader compute the vectors per vertex
void main(void)
{
  //Put the vertex in the correct coordinate system by applying the model view matrix
  vec4 vertex_camSpace = mvMatrix*vertex_worldSpace;

  varyingTextureCoordinate = textureCoordinate_input;
  gl_Position = pMatrix * vertex_camSpace;
}





]]></R2TVert>
<R2TFrag>
<![CDATA[#version 410

uniform sampler2D textureRendered;

in vec2 varyingTextureCoordinate;

out vec4 fragColor;

void main(void)
{
  //Render the texture on a quad
  fragColor = texture(textureRendered, varyingTextureCoordinate.st);
}





]]></R2TFrag>
</pipeline>
